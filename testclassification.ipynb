{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b4ff178-1f08-471e-a7d3-3da89d1eadee",
   "metadata": {},
   "source": [
    "## text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d09867-55ec-4f4a-8abd-1a4f8c660d61",
   "metadata": {},
   "source": [
    "## importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f194a70-17a5-4edb-8a7a-8c4acd9edaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as pl\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import requests \n",
    "import zipfile\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b182392-33ab-4ddd-b486-6568548fa137",
   "metadata": {},
   "source": [
    "##  stopword list to remove from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "549e04c4-d740-4259-a946-4fce58666116",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = list(ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff13ae53-1411-403a-b963-cf125afb400c",
   "metadata": {},
   "source": [
    "## extracting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90b6705e-b801-4e2b-a9a5-09d89e421d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\srish\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (15076, 52268)\n",
      "X_test shape: (3770, 52268)\n",
      "y_train shape: (15076,)\n",
      "y_test shape: (3770,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download the NLTK stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Fetch the 20 newsgroups dataset\n",
    "newsgroups = fetch_20newsgroups(subset='all', shuffle=True, random_state=42)\n",
    "\n",
    "# Extract data and labels\n",
    "data = newsgroups.data\n",
    "labels = newsgroups.target\n",
    "\n",
    "# Combine stopwords from sklearn and nltk\n",
    "combined_stopwords = set(ENGLISH_STOP_WORDS).union(set(stopwords.words('english')))\n",
    "\n",
    "# Convert the set of stopwords to a list\n",
    "stopwords_list = list(combined_stopwords)\n",
    "\n",
    "# Create a CountVectorizer instance with the combined stopwords\n",
    "vectorizer = CountVectorizer(stop_words=stopwords_list, min_df=3)  # min_df=3 to filter infrequent words\n",
    "\n",
    "# Transform the text data to feature vectors\n",
    "X = vectorizer.fit_transform(data)\n",
    "y = labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verify the shapes of the resulting arrays\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0829860a-0bb8-4863-b6fa-7bfa892b34ba",
   "metadata": {},
   "source": [
    "## fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c7bd872-1869-465a-b09e-653d2bd0faea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x_train, y_train):\n",
    "    result={}\n",
    "    class_values=set(Y_train)\n",
    "    for current_class in class_values:\n",
    "        result[current_class]={}\n",
    "        result['total data']=len(y_train)\n",
    "        current_class_rows=(y_train==curent_class)\n",
    "        x_train_current=x_train[current_class_rows]\n",
    "        y_train_current=y_train[current_class_rows]\n",
    "        num_features=x_train.shape[1]\n",
    "        for j in range(num_features+1):\n",
    "            result[current_class_][j]={}\n",
    "            all_possible_values=set(x_train[:,j-1])\n",
    "            for current_value in all_possible_values:\n",
    "                result[current_class_][j][current_value]=[x_train_current[:,j]==current_value].sum\n",
    "    return result                            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef366b2-e88b-4784-9ffe-e987da895f72",
   "metadata": {},
   "source": [
    "## probability function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebff97d8-ddd1-40b8-a8b2-cfe9b037bb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(dictionary,x,current_class):\n",
    "    output=np.log(dictionary[current_class]['total_count'])-np.log(dictionary[current_class]['toatal data'])\n",
    "    num_features=len(dictionary[current_class].keys())-1\n",
    "    for j in range(0,num_features+1):\n",
    "        xj=x[j]\n",
    "        count_current_class_with_xj=dictionary[current_class][j][xj]+1\n",
    "        count_current_class=dictionary[current_class]['toal count']+len(dictionary[current_class].keys())\n",
    "        probability=np.log(count_current_class_with_xj)-np.log(count_current_class)\n",
    "        output=output+probability\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fcf4bf-7f0d-497f-8469-e2200add9ce5",
   "metadata": {},
   "source": [
    "## prediction singlepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6231a9-756e-4492-91a6-88be7066a183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictsingle(dictionary,x):\n",
    "    classes=dictionary.keys()\n",
    "    best_p=1000\n",
    "    best_class=-1\n",
    "    first_run=True\n",
    "    for current_class in classes:\n",
    "        if current_class=='total data':\n",
    "            continue\n",
    "        p=probability(dictionary,x,current_class)\n",
    "        if first_run|| current_class>best_p:\n",
    "            best_p=p_current_class\n",
    "            best_class=current_class\n",
    "        first_run=False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb2198e-7770-460f-accc-96e30966222a",
   "metadata": {},
   "source": [
    "## predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72b4aa31-3d3c-4d0a-908b-d30d625c61dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(dictionary, x_test):\n",
    "    y_pred=[]\n",
    "    for x in x_test:\n",
    "        x_class=predictsingle(dictionary,x)\n",
    "        y_pred.append(x_class)\n",
    "    return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe846a2a-35f1-44f6-bc6a-dff6adb7d86b",
   "metadata": {},
   "source": [
    "## marked labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f9953f-7cc4-48ae-915e-221a058a5898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def marked(cols):\n",
    "    second_limit=col.mean()\n",
    "    first_limit=0.5*second_limit\n",
    "    third_limit=1.5*second_limit\n",
    "    for i in range(0,len(col)):\n",
    "        if (col[i[<first_limit):\n",
    "            col[i]=0\n",
    "        if (col[i[<second_limit):\n",
    "            col[i]=1\n",
    "        if (col[i[<third_limit):\n",
    "            col[i]=2\n",
    "        else:\n",
    "            col[i]=3\n",
    "    return col\n",
    "        \n",
    "           \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
